

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Mzzf">
  <meta name="keywords" content="">
  
    <meta name="description" content="引言 Kubernetes 作为领先的容器编排平台，其核心能力在于自动化应用的部署、扩展和管理。其中，精细化的 Pod 生命周期管理和健壮的服务发现机制是保障应用稳定、高可用的基石。本文将深入探讨 Kubernetes 在这两个方面的核心概念、底层原理、实现机制及最佳实践。       一、Pod 生命周期管理Pod 是 Kubernetes 中最小的可部署单元。理解和管理 Pod 的生命周期对于">
<meta property="og:type" content="article">
<meta property="og:title" content="Kubernetes 生命周期管理与服务发现深度解析">
<meta property="og:url" content="https://mfzzf.github.io/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/index.html">
<meta property="og:site_name" content="Mzzf&#39;s Blog">
<meta property="og:description" content="引言 Kubernetes 作为领先的容器编排平台，其核心能力在于自动化应用的部署、扩展和管理。其中，精细化的 Pod 生命周期管理和健壮的服务发现机制是保障应用稳定、高可用的基石。本文将深入探讨 Kubernetes 在这两个方面的核心概念、底层原理、实现机制及最佳实践。       一、Pod 生命周期管理Pod 是 Kubernetes 中最小的可部署单元。理解和管理 Pod 的生命周期对于">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://mfzzf.github.io/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250329130114043.png">
<meta property="og:image" content="https://mfzzf.github.io/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250329130138677.png">
<meta property="og:image" content="https://mfzzf.github.io/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250329130149736.png">
<meta property="og:image" content="https://mfzzf.github.io/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250329143150630.png">
<meta property="og:image" content="https://mfzzf.github.io/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250401111633442.png">
<meta property="og:image" content="https://mfzzf.github.io/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250401111817481.png">
<meta property="og:image" content="https://mfzzf.github.io/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250401114632259.png">
<meta property="og:image" content="https://mfzzf.github.io/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250403151308553.png">
<meta property="og:image" content="https://mfzzf.github.io/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250403151336191.png">
<meta property="og:image" content="https://mfzzf.github.io/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250403192211117.png">
<meta property="og:image" content="https://mfzzf.github.io/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250403192325067.png">
<meta property="og:image" content="https://mfzzf.github.io/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250403190538802.png">
<meta property="og:image" content="https://mfzzf.github.io/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250403191049947.png">
<meta property="og:image" content="https://mfzzf.github.io/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250403191518441.png">
<meta property="og:image" content="https://mfzzf.github.io/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250403192525332.png">
<meta property="og:image" content="https://mfzzf.github.io/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250403193034643.png">
<meta property="og:image" content="https://mfzzf.github.io/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250403193100289.png">
<meta property="og:image" content="https://mfzzf.github.io/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250403193045714.png">
<meta property="og:image" content="https://mfzzf.github.io/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250403192400424.png">
<meta property="og:image" content="https://mfzzf.github.io/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250401114121396.png">
<meta property="article:published_time" content="2025-03-29T04:34:30.000Z">
<meta property="article:modified_time" content="2025-06-23T06:35:29.141Z">
<meta property="article:author" content="Mzzf">
<meta property="article:tag" content="kubernetes">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://mfzzf.github.io/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250329130114043.png">
  
  
  
  <title>Kubernetes 生命周期管理与服务发现深度解析 - Mzzf&#39;s Blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"mfzzf.github.io","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Mzzf&#39;s blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Kubernetes 生命周期管理与服务发现深度解析"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-03-29 12:34" pubdate>
          2025年3月29日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          9.3k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          78 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">Kubernetes 生命周期管理与服务发现深度解析</h1>
            
            
              <div class="markdown-body">
                
                <p><strong>引言</strong></p>
<p>Kubernetes 作为领先的容器编排平台，其核心能力在于自动化应用的部署、扩展和管理。其中，精细化的 Pod 生命周期管理和健壮的服务发现机制是保障应用稳定、高可用的基石。本文将深入探讨 Kubernetes 在这两个方面的核心概念、底层原理、实现机制及最佳实践。</p>
<img src="/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250329130114043.png" srcset="/img/loading.gif" lazyload class="" title="image-20250329130114043">

<img src="/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250329130138677.png" srcset="/img/loading.gif" lazyload class="" title="image-20250329130138677">

<img src="/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250329130149736.png" srcset="/img/loading.gif" lazyload class="" title="image-20250329130149736">

<h2 id="一、Pod-生命周期管理"><a href="#一、Pod-生命周期管理" class="headerlink" title="一、Pod 生命周期管理"></a>一、Pod 生命周期管理</h2><p>Pod 是 Kubernetes 中最小的可部署单元。理解和管理 Pod 的生命周期对于确保应用稳定运行至关重要。Kubernetes 提供了多种机制来控制 Pod 的资源分配、健康状态和启动&#x2F;终止行为。</p>
<h3 id="1-1-Kubernetes-QoS-类别"><a href="#1-1-Kubernetes-QoS-类别" class="headerlink" title="1.1 Kubernetes QoS 类别"></a>1.1 Kubernetes QoS 类别</h3><p>Kubernetes 定义了三种 QoS (Quality of Service) 类，用于决定 Pod 的调度优先级和资源抢占&#x2F;驱逐策略。QoS 的设定基于容器的 <code>resources.requests</code> 和 <code>resources.limits</code>。</p>
<h4 id="1-Guaranteed"><a href="#1-Guaranteed" class="headerlink" title="1. Guaranteed"></a>1. <strong>Guaranteed</strong></h4><ul>
<li><strong>条件</strong>：Pod 中 <strong>所有容器</strong> 都必须同时设置 <code>requests</code> 和 <code>limits</code>，并且 <strong>所有资源类型</strong>（如 CPU, memory）的 <code>requests</code> 值必须 <strong>严格等于</strong> <code>limits</code> 值。</li>
<li><strong>特性</strong>：最高优先级。这类 Pod 拥有最强的资源保障，在节点资源紧张时，它们是最后被驱逐的对象。Kubelet 会为 Guaranteed Pod 的容器设置一个较低的 OOM (Out-Of-Memory) score adjustment 值（通常是 -998），使得它们不容易被 Linux 内核的 OOM Killer 杀死。</li>
<li><strong>场景</strong>：关键性应用，如数据库、核心业务服务。</li>
<li><strong>示例</strong>：<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># ... metadata ...</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">containers:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">app</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">nginx</span><br>    <span class="hljs-attr">resources:</span><br>      <span class="hljs-attr">requests:</span><br>        <span class="hljs-attr">memory:</span> <span class="hljs-string">&quot;500Mi&quot;</span><br>        <span class="hljs-attr">cpu:</span> <span class="hljs-string">&quot;0.5&quot;</span><br>      <span class="hljs-attr">limits:</span><br>        <span class="hljs-attr">memory:</span> <span class="hljs-string">&quot;500Mi&quot;</span><br>        <span class="hljs-attr">cpu:</span> <span class="hljs-string">&quot;0.5&quot;</span><br></code></pre></td></tr></table></figure></li>
</ul>
<h4 id="2-Burstable"><a href="#2-Burstable" class="headerlink" title="2. Burstable"></a>2. <strong>Burstable</strong></h4><ul>
<li><strong>条件</strong>：Pod 中至少有一个容器设置了 <code>requests</code> 或 <code>limits</code>，但不满足 Guaranteed 的条件（即 <code>requests</code> 和 <code>limits</code> 不完全相等，或只有部分容器设置了资源）。</li>
<li><strong>特性</strong>：中等优先级。Pod 保证获得其 <code>requests</code> 的资源量，并允许在节点资源有富余时，使用超过 <code>requests</code> 但不超过 <code>limits</code> 的资源。当节点资源紧张时，Burstable Pod 比 Guaranteed Pod 更容易被驱逐，其 OOM score adjustment 值会根据资源使用情况动态调整，但通常高于 Guaranteed Pod。</li>
<li><strong>场景</strong>：大部分 Web 应用、普通业务服务。</li>
<li><strong>示例</strong>：<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># ... metadata ...</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">containers:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">app</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">nginx</span><br>    <span class="hljs-attr">resources:</span><br>      <span class="hljs-attr">requests:</span><br>        <span class="hljs-attr">memory:</span> <span class="hljs-string">&quot;200Mi&quot;</span><br>        <span class="hljs-attr">cpu:</span> <span class="hljs-string">&quot;0.2&quot;</span><br>      <span class="hljs-attr">limits:</span><br>        <span class="hljs-attr">memory:</span> <span class="hljs-string">&quot;500Mi&quot;</span><br>        <span class="hljs-attr">cpu:</span> <span class="hljs-string">&quot;0.5&quot;</span><br></code></pre></td></tr></table></figure></li>
</ul>
<h4 id="3-BestEffort"><a href="#3-BestEffort" class="headerlink" title="3. BestEffort"></a>3. <strong>BestEffort</strong></h4><ul>
<li><strong>条件</strong>：Pod 中 <strong>所有容器</strong> 都没有设置 <code>requests</code> 和 <code>limits</code>。</li>
<li><strong>特性</strong>：最低优先级。这类 Pod 对资源没有保证，只能使用节点上其他 Pod 剩下的空闲资源。在节点资源紧张时，它们是最先被驱逐的对象。其 OOM score adjustment 值通常最高（如 1000），最容易被 OOM Killer 杀死。</li>
<li><strong>场景</strong>：开发测试环境、不重要的批处理任务。</li>
<li><strong>示例</strong>：<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># ... metadata ...</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">containers:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">app</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">nginx</span><br>    <span class="hljs-comment"># No resources defined</span><br></code></pre></td></tr></table></figure></li>
</ul>
<hr>
<h4 id="QoS-Class-在调度与驱逐中的运作机制"><a href="#QoS-Class-在调度与驱逐中的运作机制" class="headerlink" title="QoS Class 在调度与驱逐中的运作机制"></a>QoS Class 在调度与驱逐中的运作机制</h4><p>Kubernetes 的调度器 (kube-scheduler) 和节点代理 (kubelet) 在资源管理和节点压力缓解中会利用 QoS 类：</p>
<ol>
<li><strong>调度决策</strong>：调度器在选择节点时，会考虑节点的可用资源是否满足 Pod 的 <code>requests</code>。虽然 QoS 类本身不直接决定调度到哪个节点，但 Guaranteed 和 Burstable Pod 的 <code>requests</code> 会影响节点的资源预留计算，从而间接影响调度结果。高 QoS Pod 的资源需求更容易被满足。</li>
<li><strong>资源分配优先级</strong>：在节点上运行时，Guaranteed Pod 的资源得到最优先保障，其次是 Burstable Pod 的 <code>requests</code> 部分，最后是 BestEffort Pod 和 Burstable Pod 超出 <code>requests</code> 的部分。</li>
<li><strong>节点压力驱逐 (Node Pressure Eviction)</strong>：当节点出现资源压力（如 <code>MemoryPressure</code>, <code>DiskPressure</code>）时，kubelet 会按照 <code>BestEffort -&gt; Burstable -&gt; Guaranteed</code> 的优先级顺序驱逐 Pod 以回收资源。对于 Burstable Pod，如果其资源使用量超过了 <code>requests</code>，它会比仅使用 <code>requests</code> 内资源的 Burstable Pod 或 Guaranteed Pod 更早被驱逐。</li>
<li><strong>OOM Killer 行为</strong>：Linux 内核的 OOM Killer 在物理内存不足时会终止进程。Kubelet 根据 QoS 类为容器进程设置 <code>oom_score_adj</code> 值，影响 OOM Killer 的选择倾向：BestEffort (最高分，最易被杀) -&gt; Burstable (中间值) -&gt; Guaranteed (最低分，最不易被杀)。</li>
</ol>
<hr>
<h3 id="1-2-健康探针-Probes"><a href="#1-2-健康探针-Probes" class="headerlink" title="1.2 健康探针 (Probes)"></a>1.2 健康探针 (Probes)</h3><p>Kubernetes 提供三种探针来检测容器的健康状况，确保应用的可用性和自愈能力。探针由 Kubelet 在节点上执行。</p>
<ol>
<li><p><strong>Liveness Probe (存活探针)</strong></p>
<ul>
<li><strong>核心作用</strong>：判断容器是否仍在运行且功能正常。如果探测失败达到阈值，Kubelet 会杀死该容器，并根据 Pod 的 <code>restartPolicy</code> 决定是否重启。这是实现<strong>故障自愈 (Self-healing)</strong> 的关键。</li>
<li><strong>实现原理</strong>：<ul>
<li><code>exec</code>: 在容器内执行命令。如果命令退出码为 0，则成功。Kubelet 通过 CRI (Container Runtime Interface) 在容器的命名空间内执行该命令。</li>
<li><code>httpGet</code>: 向容器指定 IP、端口和路径发送 HTTP GET 请求。如果响应状态码在 200-399 之间，则成功。Kubelet 通常从节点网络命名空间发起请求（需要网络可达）。</li>
<li><code>tcpSocket</code>: 尝试与容器指定 IP 和端口建立 TCP 连接。如果连接成功建立，则成功。</li>
<li><code>grpc</code>: (较新版本支持) 向容器指定端口发送 gRPC 健康检查请求。</li>
</ul>
</li>
<li><strong>典型场景</strong>：检测死锁、无法响应请求的僵尸进程、内部状态损坏等。</li>
<li><strong>配置示例</strong>：<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">livenessProbe:</span><br>  <span class="hljs-attr">httpGet:</span><br>    <span class="hljs-attr">path:</span> <span class="hljs-string">/healthz</span><br>    <span class="hljs-attr">port:</span> <span class="hljs-number">8080</span><br>  <span class="hljs-attr">initialDelaySeconds:</span> <span class="hljs-number">15</span> <span class="hljs-comment"># 容器启动后首次探测延迟</span><br>  <span class="hljs-attr">periodSeconds:</span> <span class="hljs-number">10</span>      <span class="hljs-comment"># 探测周期</span><br>  <span class="hljs-attr">timeoutSeconds:</span> <span class="hljs-number">1</span>       <span class="hljs-comment"># 探测超时时间</span><br>  <span class="hljs-attr">failureThreshold:</span> <span class="hljs-number">3</span>     <span class="hljs-comment"># 连续失败多少次后视为失败</span><br>  <span class="hljs-attr">successThreshold:</span> <span class="hljs-number">1</span>     <span class="hljs-comment"># 连续成功多少次后视为成功 (通常为1)</span><br></code></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p><strong>Readiness Probe (就绪探针)</strong></p>
<ul>
<li><strong>核心作用</strong>：判断容器是否准备好接收外部流量。如果探测失败，Kubernetes 会将该 Pod 的 IP 从对应的 Service 的 Endpoints&#x2F;EndpointSlices 列表中移除。这确保了流量<strong>不会被转发到尚未就绪或暂时不可用的 Pod</strong>。</li>
<li><strong>网络层机制</strong>：Kubelet 将探测结果上报给 API Server。Endpoint Controller (或 EndpointSlice Controller) 监控 Pod 状态，并更新 Service 关联的 Endpoints&#x2F;EndpointSlices 对象。kube-proxy 监控这些对象的变化，并相应地更新节点上的网络规则 (iptables&#x2F;IPVS)，从而控制流量转发。</li>
<li><strong>关键应用</strong>：应用启动时的初始化（如缓存加载、数据库连接池预热）、依赖服务检查、过载保护（暂时拒绝流量）。</li>
<li><strong>配置示例</strong>：<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">readinessProbe:</span><br>  <span class="hljs-attr">exec:</span><br>    <span class="hljs-attr">command:</span> [<span class="hljs-string">&quot;cat&quot;</span>, <span class="hljs-string">&quot;/tmp/healthy&quot;</span>]<br>  <span class="hljs-attr">initialDelaySeconds:</span> <span class="hljs-number">5</span><br>  <span class="hljs-attr">periodSeconds:</span> <span class="hljs-number">5</span><br>  <span class="hljs-attr">failureThreshold:</span> <span class="hljs-number">3</span><br></code></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p><strong>Startup Probe (启动探针)</strong></p>
<ul>
<li><strong>核心作用</strong>：专门用于判断容器内应用是否已成功启动。这对于启动时间较长的应用特别有用。在 Startup Probe 成功之前，Liveness 和 Readiness Probe 会被禁用。一旦 Startup Probe 成功，Kubelet 才会开始执行 Liveness 和 Readiness Probe。如果 Startup Probe 在配置的 <code>failureThreshold * periodSeconds</code> 时间内未能成功，Kubelet 会杀死容器，如同 Liveness Probe 失败一样。</li>
<li><strong>设计哲学</strong>：解决慢启动应用可能在 Liveness Probe 超时前就被误杀的问题，提供更长的启动缓冲期。</li>
<li><strong>特殊场景</strong>：大型 Java 应用启动、机器学习模型加载、需要复杂初始化的应用。</li>
<li><strong>配置示例</strong>：<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">startupProbe:</span><br>  <span class="hljs-attr">httpGet:</span><br>    <span class="hljs-attr">path:</span> <span class="hljs-string">/startupz</span><br>    <span class="hljs-attr">port:</span> <span class="hljs-number">8080</span><br>  <span class="hljs-attr">failureThreshold:</span> <span class="hljs-number">30</span>  <span class="hljs-comment"># 总等待时间 = 30 * 10s = 300s</span><br>  <span class="hljs-attr">periodSeconds:</span> <span class="hljs-number">10</span><br></code></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
<table>
<thead>
<tr>
<th>维度</th>
<th>Liveness Probe</th>
<th>Readiness Probe</th>
<th>Startup Probe</th>
</tr>
</thead>
<tbody><tr>
<td><strong>核心使命</strong></td>
<td>故障自愈（Fail-Fast）</td>
<td>流量管控（Graceful Handling）</td>
<td>启动保护（Slow Start Shield）</td>
</tr>
<tr>
<td><strong>K8s 响应动作</strong></td>
<td>重启容器（Kill &amp; Restart）</td>
<td>从 Service Endpoints 移除&#x2F;添加</td>
<td>成功前禁用 Liveness&#x2F;Readiness</td>
</tr>
<tr>
<td><strong>失败影响域</strong></td>
<td>单个 Pod 实例</td>
<td>Service 流量分发</td>
<td>Pod 启动阶段</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<h4 id="三种探针的执行顺序与交互"><a href="#三种探针的执行顺序与交互" class="headerlink" title="三种探针的执行顺序与交互"></a>三种探针的执行顺序与交互</h4><ol>
<li><strong>启动阶段</strong>：容器启动后，如果配置了 Startup Probe，则首先执行它。Liveness 和 Readiness Probe 处于禁用状态。</li>
<li><strong>Startup 成功后</strong>：一旦 Startup Probe 首次成功，它便不再执行。Kubelet 立即开始按照各自的 <code>initialDelaySeconds</code> 和 <code>periodSeconds</code> 调度 Liveness 和 Readiness Probe。</li>
<li><strong>无 Startup Probe</strong>：如果未配置 Startup Probe，Liveness 和 Readiness Probe 会在各自的 <code>initialDelaySeconds</code> 后开始独立执行。</li>
<li><strong>并发执行</strong>：Liveness 和 Readiness Probe (在 Startup 成功后或无 Startup 时) 是并发独立执行的，它们的结果互不影响对方的执行，但共同决定 Pod 的状态和流量接收能力。</li>
</ol>
<h4 id="探针常见属性详解"><a href="#探针常见属性详解" class="headerlink" title="探针常见属性详解"></a>探针常见属性详解</h4><ul>
<li><code>initialDelaySeconds</code>: 首次探测前的延迟时间。<strong>必须</strong>仔细设置，避免应用未完全初始化就被探测。</li>
<li><code>periodSeconds</code>: 探测执行的频率。影响问题发现的速度和探测开销。</li>
<li><code>timeoutSeconds</code>: 每次探测允许的最长时间。应小于 <code>periodSeconds</code>。设置过短可能导致网络抖动下的误判。</li>
<li><code>failureThreshold</code>: 连续探测失败多少次后，判定为最终失败。增加此值可容忍瞬时故障。</li>
<li><code>successThreshold</code>: 从失败状态恢复时，需要连续探测成功多少次才判定为成功。对于 Readiness Probe，设置大于 1 可防止状态抖动（Flapping）。</li>
<li><code>terminationGracePeriodSeconds</code> (Pod 级别): 虽然不是探针属性，但影响 Liveness Probe 失败后的容器终止过程。Kubelet 发送 SIGTERM 后会等待 SIGKILL。</li>
</ul>
<h4 id="探针类型专属参数"><a href="#探针类型专属参数" class="headerlink" title="探针类型专属参数"></a>探针类型专属参数</h4><ul>
<li><strong>HTTP GET</strong>: <code>path</code>, <code>port</code>, <code>host</code>, <code>scheme</code>, <code>httpHeaders</code>。<code>host</code> 默认为 Pod IP，可指定为 <code>127.0.0.1</code> 强制探测容器内部。</li>
<li><strong>TCP Socket</strong>: <code>port</code>, <code>host</code>。</li>
<li><strong>Exec</strong>: <code>command</code>。命令在容器内执行，其资源消耗计入容器配额。</li>
</ul>
<h4 id="典型故障模式分析"><a href="#典型故障模式分析" class="headerlink" title="典型故障模式分析"></a>典型故障模式分析</h4><table>
<thead>
<tr>
<th>故障现象</th>
<th>根本原因</th>
<th>解决方案</th>
</tr>
</thead>
<tbody><tr>
<td>容器无限重启循环</td>
<td>Liveness <code>initialDelaySeconds</code> 或 <code>timeoutSeconds</code> 过短；Startup Probe 未配置或 <code>failureThreshold</code> 不足</td>
<td>调整探针参数；配置合适的 Startup Probe</td>
</tr>
<tr>
<td>Service 流量丢失</td>
<td>Readiness Probe 失败；探测逻辑本身有误</td>
<td>检查应用状态；修复探测逻辑；调整 <code>failureThreshold</code></td>
</tr>
<tr>
<td>节点 CPU&#x2F;网络 飙升</td>
<td>探测 <code>periodSeconds</code> 过短；<code>exec</code> 探针脚本复杂</td>
<td>增大 <code>periodSeconds</code>；优化脚本或改用 HTTP&#x2F;TCP</td>
</tr>
</tbody></table>
<hr>
<h3 id="1-3-Readiness-Gates"><a href="#1-3-Readiness-Gates" class="headerlink" title="1.3 Readiness Gates"></a>1.3 Readiness Gates</h3><p><code>readinessGates</code> 是一个高级特性，允许将 Pod 的就绪状态（是否加入 Service Endpoints）与<strong>外部</strong>或<strong>自定义</strong>的条件关联起来。传统的 Readiness Probe 只检查容器内部状态，而 <code>readinessGates</code> 可以等待集群级别的资源（如网络策略应用完成）或外部依赖（如数据库迁移完成）就绪。</p>
<h4 id="核心设计原理"><a href="#核心设计原理" class="headerlink" title="核心设计原理"></a>核心设计原理</h4><ol>
<li><strong>扩展状态判定</strong>：Pod 的最终就绪状态不仅取决于其容器的 Readiness Probe 结果，还取决于 <code>readinessGates</code> 中列出的所有条件的 <code>status</code> 是否为 <code>True</code>。<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql">Pod Ready <span class="hljs-operator">=</span> (<span class="hljs-keyword">All</span> Containers Ready) <span class="hljs-keyword">AND</span> (<span class="hljs-keyword">All</span> Readiness Gates Conditions <span class="hljs-keyword">are</span> <span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure></li>
<li><strong>条件注入</strong>：这些额外的条件状态通常由<strong>自定义控制器 (Operator)</strong> 或 <strong>Admission Webhook</strong> 监控相关资源或外部系统，并通过更新 Pod 的 <code>.status.conditions</code> 字段来注入。</li>
<li><strong>控制面协同</strong>：Kubelet 检查容器 Readiness Probe。Endpoint Controller 检查容器就绪状态<strong>和</strong>所有 <code>readinessGates</code> 条件的状态，共同决定是否将 Pod IP 加入 Endpoints&#x2F;EndpointSlices。</li>
</ol>
<h4 id="关键技术特性"><a href="#关键技术特性" class="headerlink" title="关键技术特性"></a>关键技术特性</h4><ul>
<li><strong>条件类型注册</strong>：在 Pod Spec 中定义需要关注的条件类型。<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Pod</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">myapp</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">readinessGates:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">conditionType:</span> <span class="hljs-string">&quot;www.example.com/ExternalServiceRegistered&quot;</span> <span class="hljs-comment"># 自定义条件</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">conditionType:</span> <span class="hljs-string">&quot;storage.example.com/VolumeAttached&quot;</span>      <span class="hljs-comment"># 可能由 CSI 驱动注入</span><br>  <span class="hljs-attr">containers:</span><br>  <span class="hljs-comment"># ... container definition ...</span><br></code></pre></td></tr></table></figure></li>
<li><strong>条件状态结构</strong>：Pod Status 中对应的条件结构。<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-attr">&quot;status&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;conditions&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>    <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Ready&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-comment">// 内建条件，表示容器是否就绪</span><br>      <span class="hljs-attr">&quot;status&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;True&quot;</span><span class="hljs-punctuation">,</span> ...<br>    <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;ContainersReady&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-comment">// 内建条件</span><br>      <span class="hljs-attr">&quot;status&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;True&quot;</span><span class="hljs-punctuation">,</span> ...<br>    <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;www.example.com/ExternalServiceRegistered&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-comment">// 自定义条件</span><br>      <span class="hljs-attr">&quot;status&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;True&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-comment">// 由外部控制器更新</span><br>      <span class="hljs-attr">&quot;lastProbeTime&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">null</span></span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;lastTransitionTime&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;2023-10-27T10:00:00Z&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;reason&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Registered&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;message&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Successfully registered with the external discovery service.&quot;</span><br>    <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;storage.example.com/VolumeAttached&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;status&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;False&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-comment">// 假设尚未就绪</span><br>      ...<br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span> ...<br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure></li>
</ul>
<h4 id="生产环境典型场景"><a href="#生产环境典型场景" class="headerlink" title="生产环境典型场景"></a>生产环境典型场景</h4><ul>
<li><strong>服务网格集成</strong>：等待 Sidecar (如 Istio Envoy) 完全初始化并准备好代理流量。<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">readinessGates:</span><br><span class="hljs-bullet">-</span> <span class="hljs-attr">conditionType:</span> <span class="hljs-string">&quot;proxy.istio.io/ready&quot;</span><br></code></pre></td></tr></table></figure></li>
<li><strong>存储系统验证</strong>：等待 CSI 驱动程序成功挂载并准备好持久卷。</li>
<li><strong>数据库迁移</strong>：等待数据库 Schema 迁移任务完成。</li>
<li><strong>配置同步</strong>：等待 ConfigMap 或 Secret 更新被应用感知并加载。</li>
<li><strong>多集群&#x2F;外部依赖</strong>：等待跨集群资源同步或外部服务注册完成。</li>
</ul>
<h4 id="与传统-Readiness-Probe-对比"><a href="#与传统-Readiness-Probe-对比" class="headerlink" title="与传统 Readiness Probe 对比"></a>与传统 Readiness Probe 对比</h4><table>
<thead>
<tr>
<th>维度</th>
<th>Readiness Probe</th>
<th>Readiness Gates</th>
</tr>
</thead>
<tbody><tr>
<td><strong>检测触发源</strong></td>
<td>Kubelet 主动探测</td>
<td>外部控制器&#x2F;系统被动通知</td>
</tr>
<tr>
<td><strong>检测范围</strong></td>
<td>容器内部状态</td>
<td>集群级&#x2F;外部系统状态</td>
</tr>
<tr>
<td><strong>关注点</strong></td>
<td>容器自身是否健康</td>
<td>Pod 是否满足服务依赖条件</td>
</tr>
<tr>
<td><strong>实现</strong></td>
<td>Kubelet 内建</td>
<td>自定义控制器 + API 更新</td>
</tr>
</tbody></table>
<h4 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h4><ul>
<li><strong>命名规范</strong>：条件类型使用域名反转格式，避免冲突。</li>
<li><strong>状态监控</strong>：监控自定义条件的状态和更新延迟。</li>
<li><strong>控制器健壮性</strong>：确保更新条件的控制器自身高可用且逻辑正确。</li>
</ul>
<hr>
<h3 id="1-4-Lifecycle-Hooks"><a href="#1-4-Lifecycle-Hooks" class="headerlink" title="1.4 Lifecycle Hooks"></a>1.4 Lifecycle Hooks</h3><p>Lifecycle Hooks 允许在容器生命周期的关键节点执行特定的操作，例如在容器启动后执行初始化任务，或在容器终止前执行清理操作。</p>
<img src="/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250329143150630.png" srcset="/img/loading.gif" lazyload class="" title="image-20250329143150630">

<ol>
<li><p><strong>postStart Hook</strong></p>
<ul>
<li><strong>触发时机</strong>：在容器<strong>创建后</strong>立即执行。注意，它与容器的<strong>入口点 (ENTRYPOINT&#x2F;CMD) 命令是异步执行的</strong>，不保证在入口点命令之前完成。</li>
<li><strong>执行方式</strong>：<ul>
<li><code>exec</code>: 在容器内执行一个命令。</li>
<li><code>httpGet</code>: 向容器内的一个端点发送 HTTP GET 请求。</li>
</ul>
</li>
<li><strong>用途</strong>：执行初始化任务，如注册服务、预加载数据等。但由于其异步性，不适合用于阻塞应用启动的关键依赖。如果 Hook 执行失败，容器会被杀死。</li>
<li><strong>示例</strong>：<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">lifecycle:</span><br>  <span class="hljs-attr">postStart:</span><br>    <span class="hljs-attr">exec:</span><br>      <span class="hljs-attr">command:</span> [<span class="hljs-string">&quot;/bin/sh&quot;</span>, <span class="hljs-string">&quot;-c&quot;</span>, <span class="hljs-string">&quot;echo Container started &gt; /var/log/startup.log&quot;</span>]<br></code></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p><strong>preStop Hook</strong></p>
<ul>
<li><strong>触发时机</strong>：在容器<strong>被终止之前</strong>执行。当 Kubelet 决定终止容器时（例如 Pod 删除、Liveness Probe 失败），会先执行 <code>preStop</code> Hook，然后再向容器发送 SIGTERM 信号。</li>
<li><strong>同步特性</strong>：<code>preStop</code> Hook 是<strong>阻塞</strong>的。Kubelet 会等待 Hook 执行完成（或超时）后，才发送 SIGTERM。整个优雅终止过程（Hook 执行 + 等待 SIGTERM 响应）的总时间受 Pod 的 <code>terminationGracePeriodSeconds</code> 限制。</li>
<li><strong>用途</strong>：执行<strong>优雅关闭 (Graceful Shutdown)</strong> 操作，如保存状态、关闭连接、从服务注册中心注销、完成正在处理的请求等。</li>
<li><strong>示例</strong>：<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">lifecycle:</span><br>  <span class="hljs-attr">preStop:</span><br>    <span class="hljs-attr">exec:</span><br>      <span class="hljs-attr">command:</span> [<span class="hljs-string">&quot;/usr/sbin/nginx&quot;</span>, <span class="hljs-string">&quot;-s&quot;</span>, <span class="hljs-string">&quot;quit&quot;</span>] <span class="hljs-comment"># Nginx 优雅关闭命令</span><br></code></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
<h4 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h4><ul>
<li><strong>执行保证</strong>：Lifecycle Hooks 的执行至少会被尝试一次。</li>
<li><strong>资源消耗</strong>：<code>exec</code> 类型的 Hook 执行会消耗容器的资源。</li>
<li><strong>超时与终止</strong>：如果 Hook 执行时间过长，超过 <code>terminationGracePeriodSeconds</code> (对于 <code>preStop</code>) 或内部超时 (对于 <code>postStart</code>)，容器可能会被强制终止 (SIGKILL)。</li>
<li><strong>与探针的关系</strong>：<code>postStart</code> 在探针开始探测之前执行。<code>preStop</code> 在容器被标记为 Terminating 状态后执行，此时 Readiness Probe 通常已失败（或即将失败）。</li>
</ul>
<hr>
<h3 id="1-5-优雅终止-TerminationGracePeriodSeconds"><a href="#1-5-优雅终止-TerminationGracePeriodSeconds" class="headerlink" title="1.5 优雅终止 (TerminationGracePeriodSeconds)"></a>1.5 优雅终止 (TerminationGracePeriodSeconds)</h3><p><code>terminationGracePeriodSeconds</code> 是 Pod Spec 中的一个字段，定义了从 Pod 被请求删除到其容器被强制终止 (SIGKILL) 之间的最大宽限时间（默认 30 秒）。这是实现应用优雅关闭的关键参数。</p>
<h4 id="Pod-删除流程详解"><a href="#Pod-删除流程详解" class="headerlink" title="Pod 删除流程详解"></a>Pod 删除流程详解</h4><ol>
<li><strong>API 请求</strong>：用户或控制器通过 API Server 请求删除 Pod。</li>
<li><strong>状态更新</strong>：Pod 对象被标记为 <code>Terminating</code> 状态，并记录 <code>deletionTimestamp</code>。</li>
<li><strong>Endpoint 移除</strong>：Endpoint Controller 将该 Pod 从 Service 的 Endpoints&#x2F;EndpointSlices 中移除（基于 Readiness 状态和 <code>Terminating</code> 状态）。此时，新的流量不再会路由到该 Pod。</li>
<li><strong>preStop Hook 执行</strong>：如果定义了 <code>preStop</code> Hook，Kubelet 会执行它。</li>
<li><strong>SIGTERM 发送</strong>：<code>preStop</code> Hook 执行完成后（或 Pod 没有 <code>preStop</code> Hook），Kubelet 向 Pod 中的每个容器的主进程发送 SIGTERM 信号。</li>
<li><strong>等待期</strong>：Kubelet 开始计时，等待 <code>terminationGracePeriodSeconds</code> 定义的时长。容器内的应用应该捕获 SIGTERM 信号，并开始执行清理工作（如完成当前请求、保存数据、关闭连接）。</li>
<li><strong>容器退出</strong>：如果容器在宽限期内自行退出（退出码 0 或非 0 均可），则优雅终止完成。</li>
<li><strong>SIGKILL 发送</strong>：如果在 <code>terminationGracePeriodSeconds</code> 结束后，容器仍未退出，Kubelet 会向其发送 SIGKILL 信号，强制终止进程。</li>
<li><strong>资源清理</strong>：Kubelet 清理与 Pod 相关的资源（如网络、存储）。</li>
<li><strong>API 对象删除</strong>：Pod 对象最终从 API Server 中删除。</li>
</ol>
<h4 id="配置与最佳实践"><a href="#配置与最佳实践" class="headerlink" title="配置与最佳实践"></a>配置与最佳实践</h4><ul>
<li><strong>设置合理值</strong>：<code>terminationGracePeriodSeconds</code> 的值应<strong>大于</strong>应用完成优雅关闭所需的<strong>最长时间</strong>（包括 <code>preStop</code> Hook 执行时间和处理 SIGTERM 的时间）。</li>
<li><strong>应用实现</strong>：应用程序<strong>必须</strong>能够正确处理 SIGTERM 信号，并在此信号触发时执行必要的清理逻辑。</li>
<li><strong>立即删除</strong>：可以通过 <code>kubectl delete pod &lt;pod-name&gt; --grace-period=0 --force</code> 来强制立即删除 Pod（跳过优雅终止期，直接发送 SIGKILL），但这通常只在调试或紧急情况下使用，可能导致数据丢失或状态不一致。</li>
</ul>
<img src="/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250401111633442.png" srcset="/img/loading.gif" lazyload class="" title="image-20250401111633442">

<img src="/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250401111817481.png" srcset="/img/loading.gif" lazyload class="" title="image-20250401111817481">

<hr>
<h2 id="二、高可用部署与更新策略"><a href="#二、高可用部署与更新策略" class="headerlink" title="二、高可用部署与更新策略"></a>二、高可用部署与更新策略</h2><p>在生产环境中，保证应用的持续可用性至关重要。Kubernetes 提供了多种机制来实现高可用部署和无缝更新。</p>
<img src="/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250401114632259.png" srcset="/img/loading.gif" lazyload class="" title="image-20250401114632259">

<h3 id="2-1-副本数量与冗余"><a href="#2-1-副本数量与冗余" class="headerlink" title="2.1 副本数量与冗余"></a>2.1 副本数量与冗余</h3><p>通过运行多个应用的多个副本（Pods），可以提高容错能力和负载处理能力。这通常通过 <code>Deployment</code>, <code>StatefulSet</code>, 或 <code>ReplicaSet</code> 控制器实现。</p>
<ul>
<li><strong><code>replicas</code> 字段</strong>：指定期望运行的 Pod 副本数量。控制器会持续监控实际运行的 Pod 数量，并在数量不足时创建新的 Pod，在数量过多时删除多余的 Pod。</li>
<li><strong>设计考量</strong>：<ul>
<li><strong>SLA 要求</strong>：根据服务等级协议确定所需的最小可用副本数。</li>
<li><strong>负载预估</strong>：根据预期流量和单个 Pod 的处理能力确定副本数。</li>
<li><strong>故障域分散</strong>：结合 Pod 反亲和性 (Pod Anti-Affinity) 或拓扑分布约束 (Topology Spread Constraints) 将副本分散到不同的节点、可用区或地域，避免单点故障影响。</li>
</ul>
</li>
</ul>
<h3 id="2-2-滚动更新策略-Rolling-Updates"><a href="#2-2-滚动更新策略-Rolling-Updates" class="headerlink" title="2.2 滚动更新策略 (Rolling Updates)"></a>2.2 滚动更新策略 (Rolling Updates)</h3><p>滚动更新是 Kubernetes <code>Deployment</code> 默认的更新策略，它允许在不中断服务的情况下逐步替换旧版本的 Pod。</p>
<ul>
<li><p><strong>工作方式</strong>：逐个或分批次地创建新版本的 Pod，同时停止旧版本的 Pod，确保在整个更新过程中，始终有一定数量的 Pod 在运行并提供服务。</p>
</li>
<li><p><strong>关键参数 (<code>spec.strategy.rollingUpdate</code>)</strong>：</p>
<ul>
<li><strong><code>maxUnavailable</code></strong>: 更新过程中允许的最大不可用 Pod 数量（相对于 <code>replicas</code>）。可以是绝对数值（如 <code>1</code>）或百分比（如 <code>25%</code>）。默认值为 <code>25%</code>。例如，<code>replicas=4</code>, <code>maxUnavailable=1</code>，表示更新时至少要有 3 个 Pod 可用。</li>
<li><strong><code>maxSurge</code></strong>: 更新过程中允许创建的、超过 <code>replicas</code> 数量的最大额外 Pod 数量。可以是绝对数值（如 <code>1</code>）或百分比（如 <code>25%</code>）。默认值为 <code>25%</code>。例如，<code>replicas=4</code>, <code>maxSurge=1</code>，表示更新时最多可以有 5 个 Pod 同时存在（新旧版本 Pod 总数）。</li>
</ul>
</li>
<li><p><strong>与 ResourceQuota 的关系</strong>：如果设置了较高的 <code>maxSurge</code>，更新时可能会临时需要更多资源（CPU, Memory）。如果命名空间设置了 ResourceQuota，需要确保配额足够容纳这些额外的 Pod，否则更新可能会失败。</p>
</li>
<li><p><strong>PodTemplateHash</strong>：Deployment 控制器通过在 ReplicaSet 和 Pod 上添加 <code>pod-template-hash</code> 标签来区分不同版本的 Pod。每次更新 <code>spec.template</code> 都会生成一个新的 hash，触发滚动更新。</p>
</li>
</ul>
<h3 id="2-3-PodDisruptionBudget-PDB"><a href="#2-3-PodDisruptionBudget-PDB" class="headerlink" title="2.3 PodDisruptionBudget (PDB)"></a>2.3 PodDisruptionBudget (PDB)</h3><p>PDB 是一种保护机制，用于限制在<strong>自愿性中断</strong>（如节点维护 <code>kubectl drain</code>、集群升级）期间，<strong>同时</strong>可以有多少个属于某个应用（由标签选择器定义）的 Pod 被中断。这确保了即使在维护操作期间，应用也能维持最低的可用性。</p>
<ul>
<li><strong>关键参数</strong>：<ul>
<li><strong><code>minAvailable</code></strong>: 指定在中断期间必须保持可用的 Pod 的最小数量或百分比。</li>
<li><strong><code>maxUnavailable</code></strong>: 指定在中断期间允许同时不可用的 Pod 的最大数量或百分比。<strong>注意：<code>minAvailable</code> 和 <code>maxUnavailable</code> 只能设置其中一个。</strong></li>
</ul>
</li>
<li><strong>工作原理</strong>：当执行可能导致 Pod 被驱逐的操作时（如 <code>kubectl drain</code>），Kubernetes 会检查相关的 PDB。如果驱逐某个 Pod 会导致低于 <code>minAvailable</code> 或超过 <code>maxUnavailable</code> 的限制，则该驱逐操作会被<strong>阻塞</strong>，直到可以安全地驱逐为止。</li>
<li><strong>重要性</strong>：PDB 对于保障关键应用在计划内维护期间的服务连续性至关重要。<strong>它不防止非自愿性中断（如节点崩溃）</strong>。</li>
</ul>
<hr>
<h2 id="三、Kubernetes-服务发现"><a href="#三、Kubernetes-服务发现" class="headerlink" title="三、Kubernetes 服务发现"></a>三、Kubernetes 服务发现</h2><p>在动态的容器环境中，Pod 的 IP 地址和数量会频繁变化。服务发现机制解决了“一个服务如何找到并访问另一个服务”的问题。</p>
<h3 id="3-1-服务发现的必要性与挑战"><a href="#3-1-服务发现的必要性与挑战" class="headerlink" title="3.1 服务发现的必要性与挑战"></a>3.1 服务发现的必要性与挑战</h3><p>微服务架构下，应用被拆分成多个独立的服务。这些服务需要相互通信。</p>
<ul>
<li><strong>必要性</strong>：<ul>
<li><strong>动态性</strong>：Pod 是短暂的，它们的 IP 会在重启、扩缩容、更新时改变。客户端不能硬编码 Pod IP。</li>
<li><strong>负载均衡</strong>：通常一个服务有多个副本，客户端需要将请求分发到这些副本上。</li>
<li><strong>解耦</strong>：服务消费者不应关心服务提供者的具体位置和数量。</li>
</ul>
</li>
<li><strong>挑战</strong>：<ul>
<li><strong>IP 地址管理</strong>：如何为服务提供一个稳定的访问入口？</li>
<li><strong>实例发现</strong>：如何动态获取服务提供者的健康实例列表？</li>
<li><strong>负载均衡实现</strong>：如何在多个实例间分发流量？</li>
<li><strong>DNS 缓存</strong>：传统 DNS 缓存可能导致服务 IP 变更感知延迟。</li>
<li><strong>跨集群&#x2F;地域</strong>：如何在多集群或混合云环境中实现服务发现？</li>
</ul>
</li>
</ul>
<img src="/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250403151308553.png" srcset="/img/loading.gif" lazyload class="" title="image-20250403151308553">

<h3 id="3-2-Kubernetes-Service-核心机制"><a href="#3-2-Kubernetes-Service-核心机制" class="headerlink" title="3.2 Kubernetes Service 核心机制"></a>3.2 Kubernetes Service 核心机制</h3><p><code>Service</code> 是 Kubernetes 中实现服务发现和负载均衡的核心抽象。它为一组功能相同的 Pod 提供了一个<strong>稳定的虚拟 IP 地址 (ClusterIP)</strong> 和 <strong>DNS 名称</strong>。</p>
<h4 id="Service-类型"><a href="#Service-类型" class="headerlink" title="Service 类型"></a>Service 类型</h4><ol>
<li><p><strong>ClusterIP</strong> (默认类型)</p>
<ul>
<li><strong>作用</strong>：为 Service 分配一个<strong>集群内部</strong>唯一的虚拟 IP 地址。该 IP 只能在集群内部访问。</li>
<li><strong>实现</strong>：kube-proxy 在每个节点上维护网络规则（iptables 或 IPVS），将发往 ClusterIP:Port 的流量<strong>负载均衡</strong>到后端健康的 Pod IP:TargetPort。</li>
<li><strong>用途</strong>：集群内部服务之间的通信。</li>
</ul>
</li>
<li><p><strong>NodePort</strong></p>
<ul>
<li><strong>作用</strong>：在 ClusterIP 的基础上，额外在<strong>每个节点</strong>上暴露一个<strong>静态端口 (NodePort)</strong>。外部客户端可以通过 <code>NodeIP:NodePort</code> 访问 Service。</li>
<li><strong>实现</strong>：kube-proxy 负责将 <code>NodeIP:NodePort</code> 的流量转发给 Service 的 ClusterIP（或直接转发给 Pod）。</li>
<li><strong>用途</strong>：将服务暴露给集群外部（通常用于测试或非生产环境，或作为外部 LB 的后端）。端口范围默认 30000-32767。</li>
</ul>
</li>
<li><p><strong>LoadBalancer</strong></p>
<ul>
<li><strong>作用</strong>：在 NodePort 的基础上，进一步向<strong>云提供商</strong>请求一个<strong>外部负载均衡器 (ELB, GLB 等)</strong>。云提供商的 LB 会将外部流量路由到各个节点的 <code>NodeIP:NodePort</code>。</li>
<li><strong>实现</strong>：需要云提供商的 Cloud Controller Manager 支持。它会自动创建、配置外部 LB，并将外部 IP 写入 Service 的 <code>status.loadBalancer.ingress</code> 字段。</li>
<li><strong>用途</strong>：将服务标准地暴露给公网或外部网络。</li>
</ul>
</li>
<li><p><strong>ExternalName</strong></p>
<ul>
<li><strong>作用</strong>：不分配 ClusterIP，也不代理任何 Pod。它将 Service 名称映射到一个<strong>外部域名 (CNAME 记录)</strong>。</li>
<li><strong>实现</strong>：集群内部的 DNS 服务（如 CoreDNS）会为该 Service 名称返回一个 CNAME 记录，指向 <code>spec.externalName</code> 指定的域名。</li>
<li><strong>用途</strong>：让集群内部的应用通过 Kubernetes Service 名称访问集群外部的服务，提供一层抽象。</li>
</ul>
</li>
</ol>
<h4 id="kube-proxy-工作模式"><a href="#kube-proxy-工作模式" class="headerlink" title="kube-proxy 工作模式"></a>kube-proxy 工作模式</h4><p>kube-proxy 是运行在每个节点上的网络代理，负责实现 Service 的路由和负载均衡规则。主要有两种模式：</p>
<ol>
<li><strong>iptables</strong> (较早，广泛使用)<ul>
<li><strong>原理</strong>：为每个 Service 创建大量的 iptables 规则，进行 DNAT (目标地址转换) 和负载均衡。</li>
<li><strong>优点</strong>：成熟稳定。</li>
<li><strong>缺点</strong>：当 Service 和 Endpoints 数量巨大时，iptables 规则数量激增，性能下降，规则更新延迟变大。规则是顺序匹配，效率不高。</li>
</ul>
</li>
<li><strong>IPVS (IP Virtual Server)</strong> (较新，性能更好)<ul>
<li><strong>原理</strong>：使用 Linux 内核的 IPVS 模块，基于哈希表进行转发，效率更高。</li>
<li><strong>优点</strong>：性能好，尤其在大规模集群中。支持更丰富的负载均衡算法。</li>
<li><strong>缺点</strong>：需要节点内核支持 IPVS 模块。</li>
</ul>
</li>
</ol>
<h4 id="Endpoints-与-EndpointSlices"><a href="#Endpoints-与-EndpointSlices" class="headerlink" title="Endpoints 与 EndpointSlices"></a>Endpoints 与 EndpointSlices</h4><ul>
<li><strong>Endpoints</strong>：早期 Kubernetes 版本中，每个 Service 对应一个 Endpoints 对象，其中包含了该 Service 代理的所有<strong>健康 Pod 的 IP 地址和端口</strong>列表。当 Service 或 Pod 发生变化时，Endpoints 对象会被更新。</li>
<li><strong>EndpointSlices</strong> (Kubernetes 1.16+ 引入，1.21+ 默认启用)<ul>
<li><strong>目的</strong>：解决 Endpoints 对象在 Pod 数量巨大时变得过大、更新效率低的问题。</li>
<li><strong>原理</strong>：将一个 Service 的 Endpoints 拆分成多个 EndpointSlice 对象。每个 Slice 包含一部分 Pod 的 IP 和端口。这样更新时只需修改涉及到的 Slice，提高了可伸缩性和性能。</li>
</ul>
</li>
</ul>
<h4 id="Headless-Service"><a href="#Headless-Service" class="headerlink" title="Headless Service"></a>Headless Service</h4><ul>
<li><strong>定义</strong>：通过将 <code>spec.clusterIP</code> 设置为 <code>None</code> 创建的 Service。</li>
<li><strong>特点</strong>：<ul>
<li>Kubernetes <strong>不会</strong>为 Headless Service 分配 ClusterIP。</li>
<li>kube-proxy <strong>不会</strong>处理这种 Service，即不提供负载均衡和代理。</li>
<li>DNS 配置不同：<ul>
<li>对于普通的 Headless Service（有 Selector），DNS 会返回<strong>所有</strong>后端 Pod 的 IP 地址 (A 记录)。</li>
<li>对于 StatefulSet 管理的 Pod，结合 Headless Service，可以为每个 Pod 提供一个<strong>唯一的、稳定的 DNS 名称</strong>，格式通常为 <code>&lt;pod-name&gt;.&lt;headless-service-name&gt;.&lt;namespace&gt;.svc.&lt;cluster-domain&gt;</code>。</li>
</ul>
</li>
</ul>
</li>
<li><strong>用途</strong>：<ul>
<li><strong>直接 Pod 访问</strong>：允许客户端自己发现所有 Pod IP，并实现自定义的负载均衡或直接连接特定 Pod。</li>
<li><strong>StatefulSet 服务发现</strong>：为有状态应用的每个实例提供稳定的网络标识。</li>
<li><strong>数据库集群</strong>等需要点对点通信的场景。</li>
</ul>
</li>
</ul>
<h3 id="3-3-DNS-在-Kubernetes-中的作用-CoreDNS"><a href="#3-3-DNS-在-Kubernetes-中的作用-CoreDNS" class="headerlink" title="3.3 DNS 在 Kubernetes 中的作用 (CoreDNS)"></a>3.3 DNS 在 Kubernetes 中的作用 (CoreDNS)</h3><p>集群 DNS 是 Kubernetes 服务发现的关键组件，通常由 CoreDNS 提供。</p>
<ul>
<li><strong>功能</strong>：为 Service 和 Pod 提供 DNS 解析服务。</li>
<li><strong>记录类型</strong>：<ul>
<li><strong>Service A 记录</strong>：<code>my-svc.my-namespace.svc.cluster-domain.example</code> 解析到 Service 的 ClusterIP。</li>
<li><strong>Headless Service A 记录</strong>：<code>my-headless-svc.my-namespace.svc.cluster-domain.example</code> 解析到所有后端 Pod 的 IP 地址列表。</li>
<li><strong>Pod A 记录 (需要配置)</strong>：<code>pod-ip-address.my-namespace.pod.cluster-domain.example</code> 解析到 Pod 的 IP 地址（通常格式为 IP 地址中的点替换为短横线）。</li>
<li><strong>StatefulSet Pod A 记录</strong>：<code>&lt;pod-name&gt;.&lt;headless-svc-name&gt;.&lt;namespace&gt;.svc.cluster-domain.example</code> 解析到特定 Pod 的 IP。</li>
<li><strong>SRV 记录</strong>：可以解析 Service 的端口信息。</li>
</ul>
</li>
<li><strong>配置</strong>：Pod 默认使用集群 DNS 进行解析（通过 <code>/etc/resolv.conf</code> 配置）。</li>
<li><strong>CoreDNS</strong>：是一个灵活、可扩展的 DNS 服务器，通过插件机制实现 Kubernetes 的服务发现逻辑。</li>
</ul>
<h3 id="3-4-服务发现面临的挑战（回顾与深化）"><a href="#3-4-服务发现面临的挑战（回顾与深化）" class="headerlink" title="3.4 服务发现面临的挑战（回顾与深化）"></a>3.4 服务发现面临的挑战（回顾与深化）</h3><ol>
<li><strong>DNS TTL 与缓存</strong>：客户端或节点 DNS 缓存可能导致 Service IP 或 Pod IP 变更后解析到旧地址。Kubernetes 内部 DNS TTL 通常较短，但外部或应用层缓存仍需注意。</li>
<li><strong>kube-proxy 性能瓶颈</strong>：iptables 模式在大规模集群下可能成为瓶颈。IPVS 模式性能更好，但仍有其限制。</li>
<li><strong>Pod 动态性影响</strong>：频繁的 Pod 启停会导致 Endpoints&#x2F;EndpointSlices 频繁更新，增加控制面和数据面（kube-proxy 更新规则）的压力。</li>
<li><strong>七层协议支持有限</strong>：原生 Service 主要工作在 L4 (TCP&#x2F;UDP)，对于 gRPC 等需要 L7 感知的负载均衡和路由支持不足（需要 Ingress 或 Service Mesh）。</li>
<li><strong>跨集群&#x2F;多集群发现</strong>：原生 Service 作用域限制在单个集群内。跨集群服务发现需要额外的解决方案（如 KubeFed, Submariner, Service Mesh）。</li>
</ol>
<hr>
<h2 id="四、Kubernetes-负载均衡"><a href="#四、Kubernetes-负载均衡" class="headerlink" title="四、Kubernetes 负载均衡"></a>四、Kubernetes 负载均衡</h2><p>负载均衡是将网络流量分发到多个后端服务实例的过程，旨在提高应用的可用性、可靠性和性能。Kubernetes 提供了多种层级的负载均衡机制。</p>
<h3 id="4-1-负载均衡基础"><a href="#4-1-负载均衡基础" class="headerlink" title="4.1 负载均衡基础"></a>4.1 负载均衡基础</h3><ul>
<li><strong>目的</strong>：<ul>
<li><strong>提高吞吐量和性能</strong>：将请求分散到多个服务器处理。</li>
<li><strong>实现高可用</strong>：当某个实例故障时，将流量切换到健康实例。</li>
<li><strong>提供伸缩性</strong>：方便地添加或移除后端实例。</li>
</ul>
</li>
<li><strong>扩展方式</strong>：<ul>
<li><strong>纵向扩展</strong>：增加单个服务器的处理能力（CPU, RAM）。有物理上限。</li>
<li><strong>横向扩展</strong>：增加服务器数量，通过负载均衡器分发流量。分布式系统的常用方式。</li>
</ul>
</li>
</ul>
<h3 id="4-2-网络基础回顾-关联-L4-L7"><a href="#4-2-网络基础回顾-关联-L4-L7" class="headerlink" title="4.2 网络基础回顾 (关联 L4&#x2F;L7)"></a>4.2 网络基础回顾 (关联 L4&#x2F;L7)</h3><p>理解网络包格式有助于理解不同负载均衡器的工作原理。</p>
<img src="/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250403151336191.png" srcset="/img/loading.gif" lazyload class="" title="image-20250403151336191">

<ul>
<li><p><strong>L4 负载均衡 (传输层)</strong>：</p>
<ul>
<li>工作在 OSI 第 4 层 (TCP&#x2F;UDP)。</li>
<li>基于 <strong>IP 地址</strong> 和 <strong>端口号</strong> (四元组：源IP、源端口、目标IP、目标端口) 来转发流量。</li>
<li><strong>不关心</strong>应用层数据内容 (如 HTTP Header)。</li>
<li><strong>优点</strong>：性能高，处理速度快。</li>
<li><strong>缺点</strong>：无法基于应用内容（如 URL 路径、请求头）进行智能路由。</li>
<li><strong>Kubernetes 体现</strong>：<code>Service</code> (ClusterIP, NodePort) 主要由 kube-proxy 实现 L4 负载均衡。</li>
</ul>
</li>
<li><p><strong>L7 负载均衡 (应用层)</strong>：</p>
<ul>
<li>工作在 OSI 第 7 层 (HTTP, HTTPS, gRPC 等)。</li>
<li>能够<strong>解析</strong>应用层协议数据。</li>
<li>基于<strong>应用内容</strong>（如 HTTP URL 路径、Host 头、Cookie、请求头等）进行更精细的流量分发和路由决策。</li>
<li><strong>优点</strong>：功能强大，路由灵活（如基于路径的路由、基于 Header 的路由、灰度发布、A&#x2F;B 测试）。可以实现 SSL 卸载、内容缓存、请求重写等高级功能。</li>
<li><strong>缺点</strong>：需要解析应用层数据，处理开销更大，性能相对 L4 较低。</li>
<li><strong>Kubernetes 体现</strong>：<code>Ingress</code> 资源及其控制器 (Nginx Ingress, Traefik 等) 实现 L7 负载均衡。Service Mesh (如 Istio, Linkerd) 也提供强大的 L7 流量管理能力。</li>
</ul>
</li>
</ul>
<h3 id="4-3-Kubernetes-中的负载均衡实现"><a href="#4-3-Kubernetes-中的负载均衡实现" class="headerlink" title="4.3 Kubernetes 中的负载均衡实现"></a>4.3 Kubernetes 中的负载均衡实现</h3><h4 id="1-Service-ClusterIP-NodePort-L4-LB-via-kube-proxy"><a href="#1-Service-ClusterIP-NodePort-L4-LB-via-kube-proxy" class="headerlink" title="1. Service ClusterIP &#x2F; NodePort (L4 LB via kube-proxy)"></a>1. Service ClusterIP &#x2F; NodePort (L4 LB via kube-proxy)</h4><ul>
<li>如前所述，kube-proxy 通过 iptables 或 IPVS 规则，将发往 Service ClusterIP 或 NodePort 的 TCP&#x2F;UDP 流量负载均衡到后端健康的 Pod。</li>
<li>默认使用<strong>随机</strong>或<strong>轮询</strong>（取决于模式和版本）策略。IPVS 支持更多算法（如最小连接数、加权轮询等）。</li>
<li>这是 Kubernetes 内建的、最基础的负载均衡形式。</li>
</ul>
<h4 id="2-Service-LoadBalancer-外部云厂商-L4-L7-LB"><a href="#2-Service-LoadBalancer-外部云厂商-L4-L7-LB" class="headerlink" title="2. Service LoadBalancer (外部云厂商 L4&#x2F;L7 LB)"></a>2. Service LoadBalancer (外部云厂商 L4&#x2F;L7 LB)</h4><ul>
<li>请求云提供商创建一个外部负载均衡器。</li>
<li>这个外部 LB 通常是 L4 LB（如 AWS Classic ELB, GCP Network LB），将流量转发到节点的 NodePort。</li>
<li>部分云厂商的实现也支持 L7 LB（如 AWS ALB, GCP HTTP(S) LB），可以直接与 Pod 通信（需要特定的 CNI 或集成方式）。</li>
<li>配置和能力受限于云提供商。</li>
</ul>
<h4 id="3-Ingress-L7-LB"><a href="#3-Ingress-L7-LB" class="headerlink" title="3. Ingress (L7 LB)"></a>3. Ingress (L7 LB)</h4><ul>
<li><strong>Ingress 资源</strong>：定义了将外部 HTTP&#x2F;HTTPS 流量路由到集群内部 Service 的规则（如基于 Host 或 Path）。</li>
<li><strong>Ingress 控制器</strong>：是一个实际运行的负载均衡器（通常是 Pod），它读取 Ingress 资源，并根据规则配置自身（如 Nginx, HAProxy, Traefik 等）来处理外部流量。</li>
<li><strong>工作流程</strong>：外部流量 -&gt; (外部 LB, 可选) -&gt; Ingress 控制器 Pod -&gt; Service -&gt; 后端 Pod。</li>
<li><strong>优点</strong>：提供标准的 L7 路由、SSL&#x2F;TLS 终止、基于名称的虚拟主机等。</li>
<li><strong>常见控制器对比</strong>：<ul>
<li><strong>Nginx Ingress</strong>: 功能丰富，社区活跃，性能较好。</li>
<li><strong>Traefik</strong>: 配置简单，自动发现能力强，原生支持 Let’s Encrypt。</li>
<li><strong>HAProxy Ingress</strong>: 高性能，稳定。</li>
<li><strong>Envoy-based (Istio Gateway, Contour, Emissary-ingress)</strong>: 云原生设计，功能强大，常与 Service Mesh 结合。</li>
</ul>
</li>
</ul>
<h3 id="4-4-不同负载均衡模式探讨-关联-K8s-实践"><a href="#4-4-不同负载均衡模式探讨-关联-K8s-实践" class="headerlink" title="4.4 不同负载均衡模式探讨 (关联 K8s 实践)"></a>4.4 不同负载均衡模式探讨 (关联 K8s 实践)</h3><p>除了 Kubernetes 内建的 Service 和 Ingress，还有其他负载均衡模式在微服务和云原生场景中常见，它们可以与 Kubernetes 结合或作为其补充。</p>
<h4 id="1-DNS-负载均衡"><a href="#1-DNS-负载均衡" class="headerlink" title="1. DNS 负载均衡"></a>1. DNS 负载均衡</h4><img src="/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250403192211117.png" srcset="/img/loading.gif" lazyload class="" title="image-20250403192211117">
<img src="/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250403192325067.png" srcset="/img/loading.gif" lazyload class="" title="image-20250403192325067">

<ul>
<li><strong>原理</strong>：在 DNS 服务器上为一个域名配置多个 A 记录，指向不同的服务器 IP。DNS 服务器在响应查询时，返回其中一个或多个 IP（通常基于轮询）。</li>
<li><strong>优点</strong>：实现简单，全局负载均衡。</li>
<li><strong>缺点</strong>：<ul>
<li><strong>生效慢</strong>：DNS 缓存导致 IP 变更传播延迟。</li>
<li><strong>无法感知后端健康</strong>：DNS 不知道后端服务器是否可用。</li>
<li><strong>负载不均</strong>：简单的轮询可能导致负载分配不均匀。</li>
</ul>
</li>
<li><strong>Kubernetes 关联</strong>：<ul>
<li>外部流量入口的第一层负载均衡（如 Route 53 将流量分发到不同区域的 K8s 集群 LoadBalancer IP）。</li>
<li>Headless Service 返回多个 Pod IP，客户端可以基于 DNS 结果做简单的负载均衡（但不推荐）。</li>
</ul>
</li>
</ul>
<h4 id="2-集中式-LB-对应-Service-LoadBalancer-Ingress"><a href="#2-集中式-LB-对应-Service-LoadBalancer-Ingress" class="headerlink" title="2. 集中式 LB (对应 Service LoadBalancer&#x2F;Ingress)"></a>2. 集中式 LB (对应 Service LoadBalancer&#x2F;Ingress)</h4><img src="/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250403190538802.png" srcset="/img/loading.gif" lazyload class="" title="image-20250403190538802">

<ul>
<li><strong>原理</strong>：所有客户端请求都先发送到一个<strong>中心化</strong>的负载均衡器（硬件 F5 或软件 Nginx&#x2F;HAProxy&#x2F;Envoy），由它将请求转发给后端服务实例。</li>
<li><strong>优点</strong>：集中管理流量策略、安全策略、健康检查。客户端实现简单。</li>
<li><strong>缺点</strong>：<ul>
<li><strong>单点瓶颈</strong>：LB 自身可能成为性能或可用性瓶颈（需要 LB 集群）。</li>
<li><strong>额外跳数</strong>：增加网络延迟。</li>
</ul>
</li>
<li><strong>Kubernetes 关联</strong>：<ul>
<li><code>Service</code> 类型 <code>LoadBalancer</code> 使用云厂商的集中式 LB。</li>
<li><code>Ingress</code> 控制器本质上是在集群内部署了一个集中式的 L7 LB。</li>
</ul>
</li>
</ul>
<h4 id="3-客户端-进程内-LB-对应-Client-Library-模式"><a href="#3-客户端-进程内-LB-对应-Client-Library-模式" class="headerlink" title="3. 客户端&#x2F;进程内 LB (对应 Client Library 模式)"></a>3. 客户端&#x2F;进程内 LB (对应 Client Library 模式)</h4><img src="/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250403191049947.png" srcset="/img/loading.gif" lazyload class="" title="image-20250403191049947">

<ul>
<li><strong>原理</strong>：负载均衡逻辑实现在<strong>客户端</strong>代码库中。客户端直接从服务注册中心（如 Consul, Etcd, Nacos 或 Kubernetes API Server）获取后端服务实例列表，并根据本地策略选择一个实例发起直接调用。</li>
<li><strong>优点</strong>：<ul>
<li><strong>无额外跳数</strong>：性能好，延迟低。</li>
<li><strong>去中心化</strong>：避免了集中式 LB 的单点瓶颈。</li>
</ul>
</li>
<li><strong>缺点</strong>：<ul>
<li><strong>客户端库耦合</strong>：需要在各种语言的客户端中实现或引入 LB 库（如 Ribbon, Spring Cloud LoadBalancer）。开发和维护成本高。</li>
<li><strong>升级困难</strong>：LB 策略更新需要升级所有客户端。</li>
</ul>
</li>
<li><strong>Kubernetes 关联</strong>：<ul>
<li>客户端应用可以直接 Watch Kubernetes API 获取 Service Endpoints&#x2F;EndpointSlices，然后在应用内部实现负载均衡。</li>
<li>gRPC 等框架支持基于 Kubernetes 服务发现的客户端负载均衡。</li>
</ul>
</li>
</ul>
<h4 id="4-Sidecar-独立进程-LB-对应-Service-Mesh-模式"><a href="#4-Sidecar-独立进程-LB-对应-Service-Mesh-模式" class="headerlink" title="4. Sidecar&#x2F;独立进程 LB (对应 Service Mesh 模式)"></a>4. Sidecar&#x2F;独立进程 LB (对应 Service Mesh 模式)</h4><img src="/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250403191518441.png" srcset="/img/loading.gif" lazyload class="" title="image-20250403191518441">

<ul>
<li><strong>原理</strong>：将负载均衡和网络通信逻辑从应用进程中剥离出来，放到一个独立的<strong>代理进程 (Sidecar)</strong> 中，该代理与应用容器一起部署在同一个 Pod 内。应用的所有出入流量都经过 Sidecar 代理。</li>
<li><strong>优点</strong>：<ul>
<li><strong>应用无感知</strong>：负载均衡、服务发现、重试、熔断、遥测、安全等网络功能对应用透明。</li>
<li><strong>语言无关</strong>：无需修改应用代码或引入特定库。</li>
<li><strong>策略集中管理</strong>：通过控制面（如 Istio Pilot）统一配置和下发策略给所有 Sidecar。</li>
</ul>
</li>
<li><strong>缺点</strong>：<ul>
<li><strong>资源开销</strong>：每个 Pod 都需要运行一个 Sidecar 代理，增加资源消耗。</li>
<li><strong>额外跳数 (本地)</strong>：流量需要在应用容器和 Sidecar 容器之间通过本地网络栈转发，有微小延迟。</li>
<li><strong>运维复杂度</strong>：引入了 Service Mesh 控制面和数据面，增加了系统的复杂性。</li>
</ul>
</li>
<li><strong>Kubernetes 关联</strong>：<ul>
<li><strong>Service Mesh (Istio, Linkerd)</strong> 是这种模式的典型实现。Sidecar (通常是 Envoy 或 linkerd-proxy) 拦截 Pod 流量，执行服务发现、负载均衡和各种流量策略。</li>
</ul>
</li>
</ul>
<h4 id="其他相关技术-LVS-NAT-LVS-DR-LVS-TUN"><a href="#其他相关技术-LVS-NAT-LVS-DR-LVS-TUN" class="headerlink" title="其他相关技术 (LVS&#x2F;NAT, LVS&#x2F;DR, LVS&#x2F;TUN)"></a>其他相关技术 (LVS&#x2F;NAT, LVS&#x2F;DR, LVS&#x2F;TUN)</h4><p>这些是 Linux Virtual Server (LVS) 实现负载均衡的具体技术模式，主要用于构建高性能的 L4 负载均衡器。</p>
<ul>
<li><strong>NAT (Network Address Translation)</strong>:<img src="/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250403192525332.png" srcset="/img/loading.gif" lazyload class="" title="image-20250403192525332">
<ul>
<li>原理：LB 修改请求报文的目标 IP (改为后端服务器 IP)，并将响应报文的源 IP (改回 LB 的 VIP)。进出流量都经过 LB。</li>
<li>缺点：LB 成为网络瓶颈。</li>
</ul>
</li>
<li><strong>DR (Direct Routing)</strong>:<img src="/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250403193034643.png" srcset="/img/loading.gif" lazyload class="" title="image-20250403193034643">
<ul>
<li>原理：LB 修改请求报文的目标 MAC 地址 (改为后端服务器 MAC)，IP 地址不变。后端服务器直接将响应报文返回给客户端（不经过 LB）。</li>
<li>优点：性能高，LB 只处理入向流量。</li>
<li>要求：LB 和后端服务器在同一个 L2 网络。后端服务器需要配置 VIP 在 non-arp 网卡上。</li>
<li><strong>Kubernetes 关联</strong>：一些基于 LVS 的 K8s 网络方案或外部 LB 可能使用 DR 模式。kube-proxy 的 IPVS 模式底层利用了类似的技术。</li>
</ul>
</li>
<li><strong>TUN (Tunneling)</strong>:<img src="/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250403193100289.png" srcset="/img/loading.gif" lazyload class="" title="image-20250403193100289">
<ul>
<li>原理：LB 将原始请求报文封装在一个新的 IP 报文中（IP Tunneling），发给后端服务器。后端服务器解包处理后，直接响应给客户端。</li>
<li>优点：支持后端服务器不在同一 L2 网络。</li>
<li>缺点：有隧道封装开销。</li>
</ul>
</li>
</ul>
<img src="/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250403193045714.png" srcset="/img/loading.gif" lazyload class="" title="image-20250403193045714">
<img src="/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250403192400424.png" srcset="/img/loading.gif" lazyload class="" title="image-20250403192400424">

<hr>
<h2 id="五、应对节点与进程中断"><a href="#五、应对节点与进程中断" class="headerlink" title="五、应对节点与进程中断"></a>五、应对节点与进程中断</h2><p>Kubernetes 环境是动态的，节点维护、升级、故障或资源压力都可能导致 Pod 被中断。需要采取策略来最小化这些中断对应用可用性的影响。</p>
<img src="/2025/03/29/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20250401114121396.png" srcset="/img/loading.gif" lazyload class="" title="image-20250401114121396">

<h3 id="5-1-常见中断场景"><a href="#5-1-常见中断场景" class="headerlink" title="5.1 常见中断场景"></a>5.1 常见中断场景</h3><ol>
<li><strong>节点维护 (Drain)</strong>：管理员主动排空节点上的 Pod 以进行维护（如内核升级、硬件更换）。Pod 会被<strong>优雅地驱逐</strong>。</li>
<li><strong>集群升级</strong>：升级 Kubernetes 控制面或节点组件 (kubelet, kube-proxy) 可能需要重启节点或 Pod。</li>
<li><strong>节点资源压力</strong>：节点 CPU、内存、磁盘或 PID 资源耗尽，Kubelet 会驱逐 Pod 以回收资源（遵循 QoS 优先级）。</li>
<li><strong>节点故障 (NotReady&#x2F;Unknown)</strong>：节点因硬件故障、网络分区或 Kubelet 崩溃而失联。控制器（如 node-controller）会在一段时间后（默认 5 分钟）将节点上的 Pod 标记为 <code>Unknown</code> 或 <code>Terminating</code> 状态，并可能在其他节点上重建这些 Pod（取决于控制器类型，如 Deployment 会重建，StatefulSet 需要特殊处理）。</li>
<li><strong>Pod 自身故障</strong>：应用 Bug 导致 Liveness Probe 失败，容器被 Kubelet 重启。</li>
<li><strong>抢占 (Preemption)</strong>：更高优先级的 Pod 需要资源时，可能会抢占节点上低优先级的 Pod。</li>
</ol>
<h3 id="5-2-缓解策略"><a href="#5-2-缓解策略" class="headerlink" title="5.2 缓解策略"></a>5.2 缓解策略</h3><ol>
<li><strong>冗余部署 (Replicas)</strong>：运行多个应用副本，是高可用的基础。</li>
<li><strong>跨故障域部署 (Anti-Affinity, Topology Spread Constraints)</strong>：将副本分散到不同节点、可用区、地域，降低单点故障影响。</li>
<li><strong>PodDisruptionBudget (PDB)</strong>：限制自愿性中断期间同时不可用的 Pod 数量，保证最低服务水平。</li>
<li><strong>优雅终止 (TerminationGracePeriodSeconds, preStop Hook)</strong>：确保 Pod 在被终止前有时间完成清理工作，保存状态。</li>
<li><strong>健康探针 (Readiness Probe)</strong>：确保流量只发送到健康的、准备就绪的 Pod。</li>
<li><strong>资源请求与限制 (Requests &amp; Limits)</strong>：合理配置资源，设置合适的 QoS 类，减少因资源不足被驱逐的风险。</li>
<li><strong>优先级与抢占 (PriorityClass)</strong>：为关键应用设置更高的优先级，使其不容易被抢占，并在资源不足时优先获得调度。</li>
<li><strong>节点容忍度 (Tolerations)</strong>：为 Pod 配置对节点污点 (Taints) 的容忍，例如容忍 <code>NotReady</code> 或 <code>Unreachable</code> 状态一段时间，避免因短暂的网络抖动导致 Pod 被过早驱逐。</li>
</ol>
<hr>
<h2 id="六、总结"><a href="#六、总结" class="headerlink" title="六、总结"></a>六、总结</h2><p>Kubernetes 提供了强大的 Pod 生命周期管理和灵活的服务发现机制。通过深入理解 QoS、健康探针、Lifecycle Hooks、优雅终止、Service、Ingress、DNS 以及各种负载均衡模式，并结合高可用部署策略（如多副本、PDB、跨域部署），可以构建出稳定、可靠、可扩展的云原生应用。掌握这些核心概念对于在 Kubernetes 环境中成功部署和运维应用至关重要。</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/kubernetes/" class="print-no-link">#kubernetes</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Kubernetes 生命周期管理与服务发现深度解析</div>
      <div>https://mfzzf.github.io/2025/03/29/生命周期管理和服务发现/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Mzzf</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年3月29日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2025/04/03/kubernetes-Service%E5%AF%B9%E8%B1%A1/" title="Kubernetes Service 深度解析">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Kubernetes Service 深度解析</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/03/28/kubernetes-CSI/" title="Kubernetes 存储机制深度解析：CSI、EmptyDir 与 HostPath">
                        <span class="hidden-mobile">Kubernetes 存储机制深度解析：CSI、EmptyDir 与 HostPath</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
